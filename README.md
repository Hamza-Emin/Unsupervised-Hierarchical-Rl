# Unsupervised Hierarchical Reinforcement Learning

Implementation of **DIAYN (Diversity is All You Need)** for unsupervised skill discovery using Soft Actor-Critic (SAC).

## ðŸŽ¯ Overview

This project implements unsupervised skill discovery where an agent learns diverse behaviors **without any external reward signal**. The agent discovers skills by maximizing mutual information between skills and states.

## ðŸ“ Project Structure

```
Unsupervised-Hierarchical-Rl/
â”œâ”€â”€ DIAYN_soft_actor_critic/
â”‚   â”œâ”€â”€ my_neural_nets.py      # Neural networks (Policy, Discriminator, Critic)
â”‚   â”œâ”€â”€ replay_buffer.py       # Experience replay buffer
â”‚   â”œâ”€â”€ dÄ±ayn_sac.py          # DIAYN-SAC agent implementation
â”‚   â”œâ”€â”€ train.py              # Training script
â”‚   â”œâ”€â”€ inference.py          # Run & visualize trained skills
â”‚   â”œâ”€â”€ record_video.py       # Record skill videos
â”‚   â””â”€â”€ README.md             # Detailed documentation
â”œâ”€â”€ diayn_agent.pth           # Trained agent (Ant-v5, hidden_dim=256)
â”œâ”€â”€ diayn_agent2.pth          # Trained agent (Ant-v5, hidden_dim=128)
â”œâ”€â”€ diayn_agent3.pth          # Trained agent (HalfCheetah-v5, hidden_dim=128)
â””â”€â”€ README.md                 # This file
```

## ðŸš€ Quick Start

### Installation

```bash
pip install gymnasium torch numpy
pip install gymnasium[mujoco]
```

### Training

```bash
cd DIAYN_soft_actor_critic
python train.py
```

### Inference (Run trained skills)

```bash
# Interactive mode
python inference.py --checkpoint ../diayn_agent3.pth --env HalfCheetah-v5 --mode interactive

# Visualize all skills
python inference.py --checkpoint ../diayn_agent3.pth --env HalfCheetah-v5 --mode visualize

# Run single skill
python inference.py --checkpoint ../diayn_agent3.pth --env HalfCheetah-v5 --mode single --skill 5
```

### Record Videos

```bash
python record_video.py
```

## ðŸ¤– Trained Agents

| Agent | Environment | Hidden Dim | Command |
|-------|-------------|------------|---------|
| `diayn_agent.pth` | Ant-v5 | 256 | `--env Ant-v5 --hidden-dim 256` |
| `diayn_agent2.pth` | Ant-v5 | 128 | `--env Ant-v5 --hidden-dim 128` |
| `diayn_agent3.pth` | HalfCheetah-v5 | 128 | `--env HalfCheetah-v5 --hidden-dim 128` |

## ðŸ§  Algorithm

DIAYN discovers diverse skills by maximizing mutual information:

```
I(S; Z) = H(Z) - H(Z|S)
```

### Neural Networks

- **Policy Network**: Takes state + skill (one-hot) â†’ outputs action distribution
- **Discriminator**: Takes state â†’ predicts which skill caused it (classifier)
- **Twin Critics**: Estimate Q-values for (state, action, skill) tuples

### Training Loop

1. Sample a random skill z
2. Policy takes actions conditioned on skill
3. Discriminator tries to identify skill from resulting states
4. Pseudo-reward = log q(z|s') - log p(z)
5. Update all networks using SAC

## ðŸ“Š Key Metrics

- **Discriminator Accuracy**: >90% means skills are well-separated
- **Displacement Std**: Higher = more diverse movement patterns
- **Pseudo Reward**: Measures how distinctive each skill's states are

## ðŸ“š References

- [DIAYN: Diversity is All You Need (Eysenbach et al., 2018)](https://arxiv.org/abs/1802.06070)
- [Soft Actor-Critic (Haarnoja et al., 2018)](https://arxiv.org/abs/1801.01290)

## ðŸ‘¤ Author

Hamza Emin

